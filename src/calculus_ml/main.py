"""
Main script to run all examples.
"""

import os
import numpy as np
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import track
from rich.tree import Tree
from rich import print as rprint
import click

# Import core functionality
from .core.linear.regression import LinearRegression
from .core.logistic.regression import LogisticRegression

# Import examples
from .examples.linear_example import run_linear_example
from .examples.linear_example_multiple import run_multiple_example
from .examples.logistic_example import run_logistic_example
from .examples.polynomial_example import main as polynomial_main
from .examples.perceptron.train import train_perceptron
from .examples.single_hidden_layer.train import main as run_neural_network

# Initialize rich console
console = Console()

# Dictionary qu·∫£n l√Ω h√¨nh ·∫£nh
IMAGES = {
    "Linear Regression": {
        "linear_regression_fit.png": "ƒê∆∞·ªùng h·ªìi quy tuy·∫øn t√≠nh v√† d·ªØ li·ªáu",
        "linear_cost_history.png": "L·ªãch s·ª≠ cost function c·ªßa linear regression",
        "multiple_regression_fit.png": "M·∫∑t ph·∫≥ng h·ªìi quy nhi·ªÅu bi·∫øn v√† d·ªØ li·ªáu",
        "multiple_cost_history.png": "L·ªãch s·ª≠ cost function c·ªßa h·ªìi quy nhi·ªÅu bi·∫øn",
        "gradient_descent_example.png": "Minh h·ªça qu√° tr√¨nh gradient descent"
    },
    "Polynomial Regression": {
        "polynomial_regression_fit.png": "So s√°nh c√°c m√¥ h√¨nh polynomial kh√°c b·∫≠c",
        "regularization_effect.png": "·∫¢nh h∆∞·ªüng c·ªßa regularization"
    },
    "Logistic Regression": {
        "logistic_decision_boundary.png": "Decision boundary c·ªßa logistic regression",
        "logistic_cost_history.png": "L·ªãch s·ª≠ cost function c·ªßa logistic regression"
    },
    "Perceptron": {
        "perceptron_training_history.png": "L·ªãch s·ª≠ training c·ªßa perceptron"
    },
    "Neural Network": {
        "neural_network_training_history.png": "L·ªãch s·ª≠ training c·ªßa neural network"
    }
}

def ensure_images_dir():
    """ƒê·∫£m b·∫£o th∆∞ m·ª•c images t·ªìn t·∫°i"""
    if not os.path.exists('images'):
        os.makedirs('images')

def print_generated_images():
    """In th√¥ng tin v·ªÅ c√°c h√¨nh ·∫£nh ƒë√£ t·∫°o"""
    tree = Tree("üìä H√¨nh ·∫£nh ƒë√£ t·∫°o")
    
    for category, images in IMAGES.items():
        category_tree = tree.add(f"üìÅ {category}")
        for img_name, description in images.items():
            img_path = os.path.join('images', img_name)
            if os.path.exists(img_path):
                size = os.path.getsize(img_path) / 1024  # Convert to KB
                category_tree.add(f"üìÑ {img_name} ({size:.1f}KB) - {description}")
            else:
                category_tree.add(f"‚ùå {img_name} (kh√¥ng t√¨m th·∫•y) - {description}")
    
    console.print("\n")
    console.print(Panel(tree, title="[bold blue]Th√¥ng tin h√¨nh ·∫£nh[/bold blue]"))
    console.print("\n")

@click.command()
@click.option('--example', type=click.Choice(['linear', 'multiple', 'polynomial', 'logistic', 'perceptron', 'neural', 'all']), 
              default='all', help='Ch·ªçn v√≠ d·ª• ƒë·ªÉ ch·∫°y')
def main(example):
    """Ch·∫°y c√°c v√≠ d·ª• v·ªÅ machine learning"""
    ensure_images_dir()
    
    if example in ['linear', 'all']:
        console.print(Panel(
            "[bold cyan]V√≠ d·ª• 1: H·ªìi quy tuy·∫øn t√≠nh ƒë∆°n gi·∫£n[/bold cyan]\n"
            "D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n di·ªán t√≠ch",
            border_style="cyan"
        ))
        run_linear_example()
    
    if example in ['multiple', 'all']:
        console.print(Panel(
            "[bold cyan]V√≠ d·ª• 2: H·ªìi quy tuy·∫øn t√≠nh nhi·ªÅu bi·∫øn[/bold cyan]\n"
            "D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n di·ªán t√≠ch v√† s·ªë ph√≤ng ng·ªß",
            border_style="cyan"
        ))
        run_multiple_example()

    if example in ['polynomial', 'all']:
        console.print(Panel(
            "[bold cyan]V√≠ d·ª• 3: Polynomial Regression v·ªõi Regularization[/bold cyan]\n"
            "D·ª± ƒëo√°n gi√° nh√† v·ªõi m√¥ h√¨nh phi tuy·∫øn v√† ki·ªÉm so√°t overfitting",
            border_style="cyan"
        ))
        polynomial_main()
    
    if example in ['logistic', 'all']:
        console.print(Panel(
            "[bold cyan]V√≠ d·ª• 4: H·ªìi quy logistic[/bold cyan]\n"
            "D·ª± ƒëo√°n k·∫øt qu·∫£ tuy·ªÉn sinh d·ª±a tr√™n ƒëi·ªÉm thi v√† GPA",
            border_style="cyan"
        ))
        run_logistic_example()

    if example in ['perceptron', 'all']:
        console.print(Panel(
            "[bold cyan]V√≠ d·ª• 5: Perceptron[/bold cyan]\n"
            "Hu·∫•n luy·ªán perceptron h·ªçc h√†m AND",
            border_style="cyan"
        ))
        
        console.print(Panel(
            "[bold yellow]C√¥ng th·ª©c Perceptron[/bold yellow]\n"
            "1. H√†m k√≠ch ho·∫°t (Activation function):\n"
            "   f(z) = 1 / (1 + e^(-z))  (Sigmoid)\n\n"
            "2. H√†m d·ª± ƒëo√°n (Prediction):\n"
            "   y_hat = f(w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + b)\n\n"
            "3. Loss function:\n"
            "   L(y, y_hat) = -(y * log(y_hat) + (1-y) * log(1-y_hat))\n\n"
            "4. Gradient descent:\n"
            "   w‚ÇÅ = w‚ÇÅ - Œ± * (y_hat - y) * x‚ÇÅ\n"
            "   w‚ÇÇ = w‚ÇÇ - Œ± * (y_hat - y) * x‚ÇÇ\n"
            "   b = b - Œ± * (y_hat - y)\n\n"
            "Trong ƒë√≥:\n"
            "- w‚ÇÅ, w‚ÇÇ: tr·ªçng s·ªë (weights)\n"
            "- b: ƒë·ªô ch·ªách (bias)\n"
            "- Œ±: learning rate\n"
            "- x‚ÇÅ, x‚ÇÇ: ƒë·∫ßu v√†o (input features)\n"
            "- y: nh√£n th·ª±c t·∫ø (true label)\n"
            "- y_hat: d·ª± ƒëo√°n (prediction)",
            border_style="yellow"
        ))
        
        train_perceptron()

    if example in ['neural', 'all']:
        console.print(Panel(
            "[bold cyan]V√≠ d·ª• 6: Neural Network[/bold cyan]\n"
            "Hu·∫•n luy·ªán m·∫°ng neural v·ªõi m·ªôt l·ªõp ·∫©n ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n XOR",
            border_style="cyan"
        ))
        
        console.print(Panel(
            "[bold yellow]C√¥ng th·ª©c Neural Network[/bold yellow]\n"
            "1. H√†m k√≠ch ho·∫°t (Activation function):\n"
            "   f(z) = 1 / (1 + e^(-z))  (Sigmoid)\n\n"
            "2. Lan truy·ªÅn ti·∫øn (Forward propagation):\n"
            "   Z1 = X¬∑W1 + b1\n"
            "   A1 = f(Z1)\n"
            "   Z2 = A1¬∑W2 + b2\n"
            "   A2 = f(Z2)\n\n"
            "3. Lan truy·ªÅn ng∆∞·ª£c (Backward propagation):\n"
            "   dZ2 = A2 - Y\n"
            "   dW2 = A1·µÄ¬∑dZ2\n"
            "   db2 = sum(dZ2)\n"
            "   dZ1 = dZ2¬∑W2·µÄ * f'(Z1)\n"
            "   dW1 = X·µÄ¬∑dZ1\n"
            "   db1 = sum(dZ1)\n\n"
            "4. C·∫≠p nh·∫≠t tham s·ªë:\n"
            "   W2 = W2 - Œ±¬∑dW2\n"
            "   b2 = b2 - Œ±¬∑db2\n"
            "   W1 = W1 - Œ±¬∑dW1\n"
            "   b1 = b1 - Œ±¬∑db1\n\n"
            "Trong ƒë√≥:\n"
            "- W1, W2: ma tr·∫≠n tr·ªçng s·ªë\n"
            "- b1, b2: vector ƒë·ªô ch·ªách\n"
            "- Œ±: learning rate\n"
            "- X: ma tr·∫≠n ƒë·∫ßu v√†o\n"
            "- Y: vector nh√£n th·ª±c t·∫ø\n"
            "- A2: d·ª± ƒëo√°n",
            border_style="yellow"
        ))
        
        run_neural_network()

    # In th√¥ng tin v·ªÅ c√°c h√¨nh ·∫£nh ƒë√£ t·∫°o
    print_generated_images()

if __name__ == "__main__":
    main() 