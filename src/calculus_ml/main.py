import os
import numpy as np
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import track
from rich.tree import Tree
from rich import print as rprint

# Import core functionality
from .core.vector import (
    add_vectors,
    dot_product,
    vector_norm,
    create_vectors,
    vector_operations,
    unit_vector_and_angle,
    vector_projection
)
from .core.cost_function import compute_cost, generate_house_data
from .core.gradient_descent import gradient_descent, compute_gradient

# Import visualization
from .visualization.cost_plot import (
    plot_cost_3d,
    plot_cost_contour,
    plot_linear_regression_fit
)
from .visualization.gradient_plot import plot_gradient_descent, plot_gradient_steps

# Initialize rich console
console = Console()

# Dictionary qu·∫£n l√Ω h√¨nh ·∫£nh
IMAGES = {
    "Cost Function": {
        "cost_function_3d.png": "B·ªÅ m·∫∑t cost function trong kh√¥ng gian 3D",
        "cost_function_contour.png": "ƒê∆∞·ªùng ƒë·ªìng m·ª©c c·ªßa cost function"
    },
    "Gradient Descent": {
        "gradient_descent_3d.png": "Qu√° tr√¨nh gradient descent tr√™n b·ªÅ m·∫∑t cost 3D",
        "gradient_descent_contour.png": "Qu√° tr√¨nh gradient descent tr√™n contour",
        "gradient_descent_steps.png": "C√°c b∆∞·ªõc c·ªßa gradient descent tr√™n d·ªØ li·ªáu",
        "cost_history.png": "L·ªãch s·ª≠ cost function qua c√°c iteration"
    }
}

def ensure_images_dir():
    """ƒê·∫£m b·∫£o th∆∞ m·ª•c images t·ªìn t·∫°i"""
    if not os.path.exists('images'):
        os.makedirs('images')

def print_generated_images():
    """In th√¥ng tin v·ªÅ c√°c h√¨nh ·∫£nh ƒë√£ t·∫°o"""
    tree = Tree("üìä H√¨nh ·∫£nh ƒë√£ t·∫°o")
    
    for category, images in IMAGES.items():
        category_tree = tree.add(f"üìÅ {category}")
        for img_name, description in images.items():
            img_path = os.path.join('images', img_name)
            if os.path.exists(img_path):
                size = os.path.getsize(img_path) / 1024  # Convert to KB
                category_tree.add(f"üìÑ {img_name} ({size:.1f}KB) - {description}")
            else:
                category_tree.add(f"‚ùå {img_name} (kh√¥ng t√¨m th·∫•y) - {description}")
    
    console.print("\n")
    console.print(Panel(tree, title="[bold blue]Th√¥ng tin h√¨nh ·∫£nh[/bold blue]"))
    console.print("\n")

def run_vector_examples():
    """Ch·∫°y c√°c v√≠ d·ª• v·ªÅ vector c∆° b·∫£n"""
    console.print("\n[bold cyan]1. Vector Operations[/bold cyan]", justify="center")
    
    # Create sample vectors
    v1, v2 = create_vectors()
    
    # Perform vector operations
    operations = vector_operations(v1, v2)
    unit_angle = unit_vector_and_angle(v1, v2)
    projection = vector_projection(v1, v2)
    
    # Create table for results
    table = Table(title="Vector Operations Results")
    table.add_column("Operation", style="cyan")
    table.add_column("Result", style="green")
    
    table.add_row("Vector 1", str(v1))
    table.add_row("Vector 2", str(v2))
    table.add_row("Sum", str(operations['v_sum']))
    table.add_row("Difference", str(operations['v_diff']))
    table.add_row("Scaled (2*v1)", str(operations['v_scaled']))
    table.add_row("Norm of v1", f"{operations['v1_norm']:.2f}")
    table.add_row("Dot product", str(operations['dot_product']))
    table.add_row("Cross product", str(operations['cross_product']))
    table.add_row("Angle between vectors", f"{unit_angle['angle']:.2f}¬∞")
    table.add_row("Projection norm", f"{projection['projection_norm']:.2f}")
    
    console.print(table)

def run_cost_and_gradient_example():
    """Ch·∫°y v√≠ d·ª• v·ªÅ cost function v√† gradient descent"""
    console.print("\n[bold cyan]2. Cost Function v√† Gradient Descent[/bold cyan]", justify="center")
    
    # T·∫°o d·ªØ li·ªáu m·∫´u v·ªÅ gi√° nh√†
    x_train, y_train = generate_house_data()
    
    # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ v√≠ d·ª•
    console.print(Panel(
        "[bold green]Th√¥ng tin v·ªÅ v√≠ d·ª•:[/bold green]\n"
        "1. D·ªØ li·ªáu m·∫´u:\n"
        "   - x: k√≠ch th∆∞·ªõc nh√† (1000 sqft)\n"
        "   - y: gi√° nh√† (1000s $)\n"
        "   - S·ªë m·∫´u: {len(x_train)}\n\n"
        "2. C√¥ng th·ª©c:\n"
        "   - H√†m d·ª± ƒëo√°n: f(x) = wx + b\n"
        "   - Cost function: J(w,b) = (1/2m) * Œ£(f(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)¬≤\n"
        "   - Gradient:\n"
        "     * ‚àÇJ/‚àÇw = (1/m) * Œ£(f(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ) * x‚ÅΩ‚Å±‚Åæ\n"
        "     * ‚àÇJ/‚àÇb = (1/m) * Œ£(f(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)\n"
        "   - C·∫≠p nh·∫≠t tham s·ªë:\n"
        "     * w = w - Œ± * ‚àÇJ/‚àÇw\n"
        "     * b = b - Œ± * ‚àÇJ/‚àÇb",
        title="Example Overview",
        border_style="cyan"
    ))
    
    # Hi·ªÉn th·ªã d·ªØ li·ªáu m·∫´u
    console.print(Panel(
        f"[bold green]D·ªØ li·ªáu training:[/bold green]\n"
        f"K√≠ch th∆∞·ªõc nh√†: {x_train}\n"
        f"Gi√° nh√†: {y_train}",
        title="Training Data",
        border_style="cyan"
    ))
    
    # T√≠nh cost function t·∫°i m·ªôt ƒëi·ªÉm
    w_example, b_example = 180, 150  # Thay ƒë·ªïi ƒëi·ªÉm minh h·ªça
    cost = compute_cost(x_train, y_train, w_example, b_example)
    
    # Debug prints
    console.print(f"\n[bold red]Debug:[/bold red]")
    console.print(f"x_train: {x_train}")
    console.print(f"y_train: {y_train}")
    console.print(f"w_example: {w_example}")
    console.print(f"b_example: {b_example}")
    console.print(f"Actual cost: {cost}")
    
    console.print(Panel(
        f"[bold green]Minh h·ªça Cost Function t·∫°i m·ªôt ƒëi·ªÉm:[/bold green]\n"
        f"Ch·ªçn ƒëi·ªÉm (w={w_example}, b={b_example}) ƒë·ªÉ minh h·ªça c√°ch t√≠nh cost function:\n"
        f"- w = {w_example}: gi√° tƒÉng {w_example}$ cho m·ªói 1000 sqft\n"
        f"- b = {b_example}: gi√° c∆° b·∫£n {b_example}$1000\n"
        f"- Cost = {cost:.2f}: ƒë·ªô l·ªách trung b√¨nh b√¨nh ph∆∞∆°ng c·ªßa d·ª± ƒëo√°n\n\n"
        f"[yellow]Gi·∫£i th√≠ch:[/yellow]\n"
        f"T·∫°i ƒëi·ªÉm n√†y, m√¥ h√¨nh c√≥ m·ªôt s·ªë sai s·ªë trong d·ª± ƒëo√°n:\n"
        f"- Nh√† 1000 sqft: d·ª± ƒëo√°n = {w_example*1 + b_example} = {w_example*1 + b_example:.0f} (th·ª±c t·∫ø: 300)\n"
        f"- Nh√† 2000 sqft: d·ª± ƒëo√°n = {w_example*2 + b_example} = {w_example*2 + b_example:.0f} (th·ª±c t·∫ø: 500)\n"
        f"- Nh√† 3000 sqft: d·ª± ƒëo√°n = {w_example*3 + b_example} = {w_example*3 + b_example:.0f} (th·ª±c t·∫ø: 700)\n"
        f"- Nh√† 4000 sqft: d·ª± ƒëo√°n = {w_example*4 + b_example} = {w_example*4 + b_example:.0f} (th·ª±c t·∫ø: 900)\n"
        f"- Nh√† 5000 sqft: d·ª± ƒëo√°n = {w_example*5 + b_example} = {w_example*5 + b_example:.0f} (th·ª±c t·∫ø: 1100)\n\n"
        f"[yellow]L∆∞u √Ω:[/yellow] ƒê√¢y l√† m·ªôt ƒëi·ªÉm b·∫•t k·ª≥ tr√™n b·ªÅ m·∫∑t cost function.\n"
        f"Trong ph·∫ßn ti·∫øp theo, ch√∫ng ta s·∫Ω t√¨m ƒëi·ªÉm t·ªëi ∆∞u (w*, b*) c√≥ cost th·∫•p nh·∫•t.",
        title="Cost Function Evaluation",
        border_style="cyan"
    ))
    
    # V·∫Ω ƒë·ªì th·ªã cost function
    with console.status("[bold green]T·∫°o ƒë·ªì th·ªã cost function..."):
        plot_cost_3d(x_train, y_train, w_range=(100, 300), b_range=(-200, 200), save_as='cost_function_3d.png')
        plot_cost_contour(x_train, y_train, w_range=(100, 300), b_range=(-200, 200), save_as='cost_function_contour.png')
    
    # Th·ª±c hi·ªán gradient descent
    initial_w, initial_b = 100, 0
    iterations = 1000
    alpha = 0.01
    
    console.print(Panel(
        f"[bold green]Th√¥ng tin gradient descent:[/bold green]\n"
        f"- Learning rate (Œ±): {alpha}\n"
        f"- S·ªë iteration: {iterations}\n"
        f"- Tham s·ªë kh·ªüi t·∫°o: w = {initial_w}, b = {initial_b}",
        title="Gradient Descent Setup",
        border_style="cyan"
    ))
    
    with console.status("[bold green]Running gradient descent..."):
        w_final, b_final, J_hist, p_hist = gradient_descent(
            x_train, y_train, initial_w, initial_b, alpha, iterations, compute_cost)
    
    # T√°ch l·ªãch s·ª≠ tham s·ªë
    w_hist = [p[0] for p in p_hist]
    b_hist = [p[1] for p in p_hist]
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    console.print(Panel(
        f"[bold green]K·∫øt qu·∫£ t·ªëi ∆∞u sau gradient descent:[/bold green]\n"
        f"1. Tham s·ªë t·ªëi ∆∞u (w*, b*):\n"
        f"   w* = {w_final:.2f}\n"
        f"   b* = {b_final:.2f}\n"
        f"2. Ph∆∞∆°ng tr√¨nh h·ªìi quy t·ªëi ∆∞u:\n"
        f"   y = {w_final:.2f}x + {b_final:.2f}\n"
        f"3. Cost t·ªëi ∆∞u: {J_hist[-1]:.4f}\n\n"
        f"[yellow]So s√°nh v·ªõi ƒëi·ªÉm minh h·ªça:[/yellow]\n"
        f"- ƒêi·ªÉm minh h·ªça (w={w_example}, b={b_example}): Cost = {cost:.2f}\n"
        f"- ƒêi·ªÉm t·ªëi ∆∞u (w*={w_final:.2f}, b*={b_final:.2f}): Cost = {J_hist[-1]:.4f}\n"
        f"‚Üí ƒêi·ªÉm t·ªëi ∆∞u c√≥ cost th·∫•p h∆°n, nghƒ©a l√† m√¥ h√¨nh d·ª± ƒëo√°n ch√≠nh x√°c h∆°n.",
        title="Optimization Results",
        border_style="cyan"
    ))
    
    # V·∫Ω ƒë·ªì th·ªã gradient descent
    with console.status("[bold green]T·∫°o ƒë·ªì th·ªã gradient descent..."):
        plot_gradient_descent(x_train, y_train, w_hist, b_hist, J_hist, compute_cost, save_as='gradient_descent_3d.png')
        plot_gradient_steps(x_train, y_train, w_hist, b_hist, compute_cost, save_as='gradient_descent_steps.png')

def main():
    """H√†m main ch·∫°y t·∫•t c·∫£ c√°c v√≠ d·ª•"""
    console.print(Panel.fit(
        "[bold blue]·ª®ng D·ª•ng Gi·∫£i T√≠ch v√† H·ªçc M√°y[/bold blue]\n"
        "[italic]Minh h·ªça c√°c kh√°i ni·ªám c∆° b·∫£n trong h·ªçc m√°y[/italic]",
        border_style="blue"
    ))
    
    # Ensure images directory exists
    ensure_images_dir()
    
    # Ch·∫°y c√°c v√≠ d·ª•
    for example in track([
        run_vector_examples,
        run_cost_and_gradient_example
    ], description="Running examples..."):
        example()
    
    # In th√¥ng tin v·ªÅ c√°c h√¨nh ·∫£nh ƒë√£ t·∫°o
    print_generated_images()

if __name__ == "__main__":
    main() 